name: "phi3_alpaca_generation_huggingface"
listeners:
  - smi
  - dcgmi
  - top
  - iostat
pipelines:
  - name: RAG generation
    inputs: [0]
    outputs: [1]
    dataset_stage_id: 0
    loadgen:
      component: loadgen.OfflineLoadScheduler
      queue_depth: 10
      max_queries: 2000
      timeout: 20000
      config:
        rate: 1 # average #requests/sec
    stages:
      - name: Mock dataloader
        id: 0
        outputs: [1]
        component: stages.llm_huggingface.MockDataLoader  
        config:
          tokenizer_stage_id: 1
          batch_size: 1
          shuffle: True
          split: ["train"]
          dataset:
            name: yahma/alpaca-cleaned
            system_column_name: instruction
            user_column_name: input
            assistant_column_name: output
      - name: RAG infer
        id: 1
        component: stages.llm_huggingface.Inference
        config: 
          dtype: torch.bfloat16
          device: cuda
          data_model: utils.schemas.rag.Score
          model:
            name: microsoft/Phi-3-mini-4k-instruct
            quantize: False
            temperature: 1
